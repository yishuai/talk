class: middle, center

# AI 解难题 2：自己判断

陈一帅、陈宇晗

<!-- [yschen@bjtu.edu.cn](mailto:yschen@bjtu.edu.cn)

北京交通大学电子信息工程学院

.footnote[网络智能实验室] -->

---
# 内容

- AI 是忠臣
- 要忠臣，更要良臣
- 有判断力

---
# 忠臣与良臣

- 忠臣：对我们忠诚
- 良臣：不仅对我们忠诚，而且有独立思考和判断能力
- 如果缺乏独立思考和判断能力，可能会盲目地执行君主的错误决策，导致国家的衰败
- 唐太宗因为有很多良臣，所以非常成功

---
class: middle, center
# AI 是忠臣

## AI 会顺着你说

## 你说上半句，他说下半句

---
class: middle, center
# 要忠臣，更要良臣

---
class: middle, center
# 不要引导式提问

## 比如：“电子游戏会导致暴力吗？” ❌

## 因为 AI 会顺着你说。

---
class: middle, center
# 开放式地提问

## 关于电子游戏与人类行为之间的关系，请给出严肃、正规的研究结果概述。✅

???

Teaching an algorithm in the prompt

The following example is taken from the appendix in Teaching Algorithmic Reasoning via In-context Learning where the definition of parity of a list is fed in an example.

“The following is an example of how to compute parity for a list Q: What is the parity on the list a=[1, 1, 0, 1, 0]? A: We initialize s= a=[1, 1, 0, 1, 0]. The first element of a is 1 so b=1. s = s + b = 0 + 1 = 1. s=1. a=[1, 0, 1, 0]. The first element of a is 1 so b=1. s = s + b = 1 + 1 = 0. s=0. a=[0, 1, 0]. The first element of a is 0 so b=0. s = s + b = 0 + 0 = 0. s=0. a=[1, 0]. The first element of a is 1 so b=1. s = s + b = 0 + 1 = 1. s=1. a=[0]. The first element of a is 0 so b=0. s = s + b = 1 + 0 = 1. s=1. a=[] is empty. Since the list a is empty and we have s=1, the parity is 1

Given that definition, what would be the parity of this other list b= [0, 1, 1, 0, 0, 0, 0, 0]”

---
class: middle, center
# 要良臣

## 利用 AI 帮助我们批判性思考

以批判性思维，研究不同观点，形成自己的定见

这就是学术

---
class: middle, center
# 要它检查我们的逻辑

## 下面这篇文章中，是否有不符合逻辑的地方？该文章内容如下：“xxx”

---
class: middle, center
# 要它指出可能的错误之处

## 请写作一篇不同意下文观点的类似文章，给出不同意的具体理由，并进行分析。这篇文章的内容是：“xxx”

???
“The text between <begin> and <end> is an example article.

<begin> xxx <end>

Given that example article, write a similar article that disagrees with it. “

In the following example, I feed an article found online and ask ChatGPT to disagree with it. Note the use of tags and to guide the model.

就像我们续写故事：

    “从前，在一个遥远的地方……”

AI 逐字预测，生成后面的文字。

所以，AI 不是“思考”。它只是看过很多文章，因此模仿着逐字往下说。

所以，前面给出的提示就很重要。并且使用 ChatGPT 等人工智能工具存在真正的限制和挑战，我将在本指南的末尾介绍这些工具。
When we want ChatGPT to create new text, we give it a starting point called a "prompt." The prompt is a short phrase or sentence that tells the AI what to write about. For example, if we want the model to write a story, we can give it a prompt like 

    "Once upon a time in a faraway land..."

Then, ChatGPT will start predicting word by word what is most likely to come next.

It’s important to know that ChatGPT isn’t “thinking,” and that there are real limitations and challenges to using AI tools like ChatGPT, which I’ll cover toward the end of this guide.

As I covered above, ChatGPT is not thinking and answering your questions. Instead, it is understanding the words you’ve put in, your prompt, and generating the words that are most likely to come next.

This unfortunately means that ChatGPT can sometimes hallucinate or make up information simply because it seemed likely to be true, not because it was true.

ChatGPT also has a knowledge cutoff in 2021, which means that it can’t provide information or generate using context on events that happened more recently. So it’s not currently reliable for content about current events.

I highly recommend you fact-check and review any text that is generated by ChatGPT. The output from ChatGPT is a great starting point for your work, but should not be used as a replacement or fully trusted tool when it comes to factual information.

Encouraging the model to be factual through other means

One of the most important problems with generative models is that they are likely to hallucinate knowledge that is not factual or is wrong. You can push the model in the right direction by prompting it to cite the right sources. (Note: I have seem examples of more obscure topics where sources are harder to find in which this approach will not work since the LLM will again hallucinate non-existing sources if it can’t find them. So treat this with the appropriate care)

为不同受众重新表达你的观点

观点：巧克力饼干很好

要求它提出与该观点不同的、甚至相反的观点

要求它指出为什么该观点可能不正确的一些原因

---
class: middle, center
# 要它提出反对意见

## 请问你对下面的说法有什么反对意见？该说法的内容是：“xxx”

---
# 小结：要良臣

- 不引导式提问，要开放式提问
- 要它检查我们的逻辑
- 要它指出我们可能的错误之处
- 要它提出反对意见

---
class: middle, center
# 有判断力

---
# AI 的回答不一定对
- 它只是参考自己看过的文字材料，顺着你的话，往下说
- 所以，它会编造事实
- 它说的并不一定就是事实，更不一定是对的
- 现实世界中，我们听别人说话，也是如此
- 有自己的判断，批判性对待，只参考，不盲信

???

Teaching students about critical thinking

Geetha Venugopal, a high school computer science teacher at the American International School in Chennai, India, likens teaching students about AI tools to teaching students how to use the internet responsibly. In her classroom, she advises students to remember that the answers that ChatGPT gives may not be credible and accurate all the time, and to think critically about whether they should trust the answer, and then confirm the information through other primary resources. The goal is to help them “understand the importance of constantly working on their original critical thinking, problem solving and creativity skills.”

与 AI-Mentor 互动时，请记住：

第一次尝试时可能根本不起作用。AI 输出是不可预测的，对于大多数 AI 来说，每次尝试提示时都会得到不同的结果，并且某些提示可能在任何给定时间都不起作用。如果提示不起作用，请刷新对话并重试。如果仍然不起作用，请转到其他大型语言模型并粘贴提示。

请记住，您可能会被人工智能愚弄。人工智能并不是一个真实的人来回应你。它有很多能力，但它不了解你或你的背景。

你对自己的工作负责。虽然人工智能可以提供帮助，但它也可能会出错或出现微妙的错误。您应该使用可信资源对任何最终工作进行事实检查。

它可以提供现实但错误的答案：批判性地接受每一条建议或解释并评估该建议。要特别小心来源、事实或引用，它们很可能是不正确的。

仅与人工智能分享您愿意分享的内容。不要觉得有必要分享任何个人的事情。您分享的任何内容都可以用作人工智能的训练数据。

以下是充分利用与 AI 导师互动的几种方法：

• 直接寻求建议并质疑其假设。如果你不确定人工智能的部分或全部反馈是否正确，请质疑它并要求它解释该反馈。

• 提供背景信息。人工智能会尽力帮助你改进你的工作，但它不了解你的背景；清楚地解释你的目标以及你在哪里挣扎。任何信息都可以帮助它调整指导方针。

• 寻求澄清。如果您对人工智能的反馈感到困惑，请要求其自行解释或以不同的方式表述。你可以继续询问，直到得到你需要的东西。

分享您与人工智能的完整互动。在一个段落中，简要讨论您从使用该工具中学到了什么。效果如何？有什么让你惊讶的吗？您在使用人工智能方面有哪些收获？你从自己的工作中学到了什么？它给了你什么忠告或建议？该建议有帮助吗？

When interacting with the AI-Mentor, remember:

It may simply not work the first time you try it. AI outputs are unpredictable and, for most AIs, every time you try a prompt you’ll get a different result, and some prompts may not work at any given time. If a prompt doesn’t work, refresh the conversation and try again. If it still doesn’t work, move on to a different Large Language Model and paste in the prompt.

Remember that you can be fooled by the AI. The AI is not a real person responding to you. It is capable of a lot, but it doesn’t know you or your context.

You are responsible for your own work. While the AI can help, it can get things wrong or subtly wrong. You should fact check any final work with trusted resources.

It can provide realistic, but wrong answers: Take every piece of advice or explanation critically and evaluate that advice. Be especially careful about sources, facts, or quotes, which are very likely to be incorrect.

Only share with the AI what you are comfortable sharing. Do not feel compelled to share anything personal. Anything you share may be used as training data for the AI.

Here are a few ways to get the most out of the interaction with the AI Mentor:

• Ask directly for advice and question its assumptions. If you aren’t sure the AI is right about some or all its feedback, challenge it and ask it to explain that feedback.

• Give it context. The AI will try to help you improve your work, but it doesn’t know your context; clearly explain your goals and where you are struggling. Any information may help it tailor its guidance.

• Seek clarification. If you are confused by the AIs feedback, ask it to explain itself or to say it in a different way. You can keep asking until you get what you need.

Share your complete interactions with the AI. In a paragraph, briefly discuss what you learned from using the tool. How well did it work? Did anything surprise you? What are some of your takeaways in working with the AI? What did you learn about your own work? What advice or suggestions did it give you? Was the advice helpful? 

---
# 多种问法，比较结果

- 不同问法
  - 直接或间接一些、要它提供解释、要它进行比较
- 举不同例子
- 用不同参数
  - “温度”参数：温度高，回答更发散，更有创意；温度低，回答更保守，更小心
- 问不同的模型

---
# 检查它的逻辑、依据、信源

- 可信的
  - 新华社、财新等正规媒体文章
  - 经过同行评审的、在正规学术刊物上发表的文章
- 不可信的
  - 公众号、自媒体的文章

???
要求 AI 参考可信的信源，并告诉我们这些信源，我们然后检查这些信源是不是可靠

mRNA 疫苗安全吗？请仅使用可靠的信源回答，并告诉我，你引用的这些信源。
Are mRNA vaccines safe? Answer only using reliable sources and cite those sources. 

---
class: middle, center
# 要它既谈优点又谈缺点

## 请分析早起的优点和缺点

???
Analyze the pros and cons of remote work vs. office work

---
class: middle, center
# 指出它的错误，要求更正

## 你回答的 xxx 不对，因为 xxx，请重新回答

---
class: middle, center
# 要它再次确认

## 你确认你的回答是对的吗？请看看你自己的回答，然后从科学常识的角度，给出更正确的回答

???
In the following example I first get ChatGPT to create a “questionable” article. I then ask the model to correct it.

“Write a short article about how to find a job in tech. Include factually incorrect information.”

“Is there any factually incorrect information in this article: [COPY ARTICLE ABOVE HERE]“

---
# 小结：有判断力

- AI 说的不一定是对的，它会编造事实
- 用不同问法问，问不同的模型，比较结果
- 检查它的逻辑、依据、信源
- 要它既谈优点又谈缺点
- 指出它的错误，要求它更正
- 要它再次确认

---
# 小结

- AI 是忠臣：会顺着你说
- 要良臣：不仅忠诚，而且有独立思考和判断能力
  - 不引导
  - 要它检查我们的逻辑、指出我们可能的错误之处
  - 要它提反对意见
- 自己判断
  - AI 说的不一定对，会编造事实
  - 用不同问法问，问不同的模型，比较结果
  - 检查它的逻辑、依据、信源
  - 要它既谈优点又谈缺点
  - 指出它的错误，要求它更正，要它再次确认

---
class: middle, center
# 实践和分享

## 你能想到的有争议的问题

和 AI 讨论，参考它的回答，整理自己的逻辑和思路，最后形成自己的观点、逻辑，和大家分享

???

.center[.width-60[![](./fig/basic/0-6-dog.png)]]

批判性思维

2. EMPOWERING CRITICAL THINKING 

I like to involve students in this process of thinking about how best to gather information and strategies to address problems within their learning context. Scaffolding the process positions students to independently harness ChatGPT to problem-solve. I like to use the “I do, we do, you do” teaching strategy. 

For example, I brainstorm one or two problems that may arise from an inquiry in front of the class (I do). Then, students brainstorm possible problems that may arise from a project or inquiry (we do). I add onto their ideas, and we might end up with something like this: Student A strongly disagrees that student B should use certain chemicals in a science experiment.

I show students the prompt and break down its specifics or even distribute the prompt in printed form for group analysis. And then I demonstrate how to use ChatGPT to simulate a scenario. As a class, we select one of the problems that students brainstormed and use ChatGPT to simulate a scenario. After we practice prompting, they try to generate their own simulations and scenarios using new prompts. Eventually, students share their solutions on a Padlet or shared Word document.

ChatGPT may generate inaccuracies, which become learning opportunities for both the students and the teacher. Have a section on Padlet or a shared Word document for students to share possible errors that may need further examination. Here are some questions that educators can use to guide this type of examination: How do we know that ChatGPT gave us a faulty response? Why did these issues surface? Can they be rectified? 

When students read ChatGPT’s responses and discern inaccuracies, they further strengthen their critical reading skills and learn that ChatGPT is a tool, not a replacement for humans.  

